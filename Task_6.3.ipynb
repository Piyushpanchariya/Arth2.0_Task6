{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,photo = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [  0,   0,   2],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [  0,   0,   2],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [  0,   0,   1],\n",
       "        [  0,   0,   1],\n",
       "        [  0,   0,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[132, 116, 118],\n",
       "        [132, 115, 117],\n",
       "        [134, 115, 119],\n",
       "        ...,\n",
       "        [157, 152, 159],\n",
       "        [158, 152, 159],\n",
       "        [158, 152, 159]],\n",
       "\n",
       "       [[132, 116, 119],\n",
       "        [133, 115, 119],\n",
       "        [134, 115, 119],\n",
       "        ...,\n",
       "        [154, 153, 155],\n",
       "        [154, 154, 154],\n",
       "        [155, 155, 155]],\n",
       "\n",
       "       [[135, 118, 120],\n",
       "        [131, 116, 117],\n",
       "        [131, 118, 117],\n",
       "        ...,\n",
       "        [154, 155, 154],\n",
       "        [153, 156, 153],\n",
       "        [151, 154, 152]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n",
      "no face found\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret,video=cap.read()\n",
    "    \n",
    "    face = model.detectMultiScale(video)\n",
    "    if len(face)==0:\n",
    "        print(\"no face found\")\n",
    "    else:\n",
    "        \n",
    "        x=face[0][0]\n",
    "        y=face[0][1]\n",
    "        x1=x+face[0][2]\n",
    "        y1=y+face[0][3]\n",
    "        #x,y,x1,y1 = face\n",
    "        video_face=cv2.rectangle(video,(x,y),(x1,y1),[0,255,0],5)\n",
    "        cv2.imshow(\"original\",video_face)\n",
    "        crop_video = video[y:y+y1,x:x+x1]\n",
    "        #video_face[y:y+y1,x:x+x1]=cv2.GaussianBlur(video_face[y:y+y1,x:x+x1],(3,65),25)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #crop_video = video[y1:y2,x1:x2]\n",
    "        cv2.imshow(\"cropped_video\",crop_video)\n",
    "        if cv2.waitKey(100)==13:\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,photo =cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imread(photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
